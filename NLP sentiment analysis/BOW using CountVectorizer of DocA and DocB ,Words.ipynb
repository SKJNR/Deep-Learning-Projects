{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BOW using CountVectorizer of DocA and DocB ,Words "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "G:\\DOWNLOADS\\Programs\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import string\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get an article\n",
    "textA = open('AI.txt', encoding=\"utf-8\").read()\n",
    "lower_case = textA.lower()\n",
    "# str.maketrans removes any punctuations \n",
    "cleaned_text = lower_case.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "# Using word_tokenize to tokenize sentence into words\n",
    "tokenized_wordsA = word_tokenize(cleaned_text, \"english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vector on Document A using BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bag of words : ['100', '400', '50', 'about', 'acquired', 'ai', 'algorithm', 'algorithms', 'almost', 'also', 'an', 'anandkumar', 'and', 'anima', 'annual', 'any', 'application', 'applied', 'are', 'artificial', 'asked', 'at', 'autonomous', 'be', 'beginning', 'business', 'businessoriented', 'by', 'call', 'caltech', 'capital', 'centers', 'companies', 'company', 'compelling', 'compiled', 'computer', 'confidentially', 'consideration', 'create', 'creating', 'customer', 'customers', 'cut', 'data', 'deployed', 'details', 'developers', 'difficult', 'director', 'drug', 'eight', 'eligible', 'enables', 'encourage', 'entries', 'esoteric', 'every', 'expert', 'field', 'finance', 'financials', 'firms', 'focus', 'focused', 'for', 'forbes', 'from', 'funded', 'funding', 'greater', 'had', 'highest', 'history', 'how', 'hype', 'identified', 'identify', 'impact', 'improve', 'in', 'included', 'including', 'incubated', 'industrial', 'industry', 'information', 'intelligence', 'interesting', 'is', 'it', 'its', 'jargon', 'judge', 'judges', 'language', 'large', 'largely', 'leading', 'learn', 'learning', 'like', 'list', 'machine', 'machinelearning', 'machines', 'magic', 'making', 'manufacturing', 'meaningful', 'meritech', 'model', 'most', 'natural', 'not', 'nvidia', 'of', 'on', 'opaque', 'open', 'option', 'or', 'our', 'outsiders', 'panel', 'partnered', 'partners', 'plagued', 'private', 'privatelyheld', 'problem', 'process', 'processing', 'professor', 'programs', 'provide', 'quantitative', 'received', 'relates', 'relentless', 'research', 'revenue', 'says', 'scores', 'second', 'see', 'sequoia', 'side', 'some', 'spin', 'spoken', 'submission', 'submit', 'systems', 'tasks', 'tech', 'techniques', 'technology', 'that', 'the', 'their', 'then', 'there', 'through', 'to', 'total', 'transparency', 'understand', 'us', 'usbased', 'usefully', 'using', 'valuation', 'vc', 'vehicle', 'venture', 'vision', 'was', 'ways', 'were', 'where', 'which', 'with', 'written', 'yet']\n"
     ]
    }
   ],
   "source": [
    "# This step will convert text into tokens \n",
    "vect1 = CountVectorizer()\n",
    "\n",
    "vect1.fit_transform(tokenized_wordsA)\n",
    "print(\"bag of words :\",vect1.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'artificial': 19,\n",
       " 'intelligence': 87,\n",
       " 'is': 89,\n",
       " 'beginning': 24,\n",
       " 'to': 164,\n",
       " 'be': 23,\n",
       " 'usefully': 170,\n",
       " 'deployed': 45,\n",
       " 'in': 80,\n",
       " 'almost': 8,\n",
       " 'every': 57,\n",
       " 'industry': 85,\n",
       " 'from': 67,\n",
       " 'customer': 41,\n",
       " 'call': 28,\n",
       " 'centers': 31,\n",
       " 'and': 12,\n",
       " 'finance': 60,\n",
       " 'drug': 50,\n",
       " 'research': 140,\n",
       " 'yet': 184,\n",
       " 'the': 159,\n",
       " 'field': 59,\n",
       " 'also': 9,\n",
       " 'plagued': 127,\n",
       " 'by': 27,\n",
       " 'relentless': 139,\n",
       " 'hype': 75,\n",
       " 'opaque': 118,\n",
       " 'jargon': 92,\n",
       " 'esoteric': 56,\n",
       " 'technology': 157,\n",
       " 'making': 107,\n",
       " 'it': 90,\n",
       " 'difficult': 48,\n",
       " 'for': 65,\n",
       " 'outsiders': 123,\n",
       " 'identify': 77,\n",
       " 'most': 112,\n",
       " 'interesting': 88,\n",
       " 'companies': 32,\n",
       " 'cut': 43,\n",
       " 'through': 163,\n",
       " 'spin': 149,\n",
       " 'forbes': 66,\n",
       " 'partnered': 125,\n",
       " 'with': 182,\n",
       " 'venture': 175,\n",
       " 'firms': 62,\n",
       " 'sequoia': 146,\n",
       " 'capital': 30,\n",
       " 'meritech': 110,\n",
       " 'create': 39,\n",
       " 'our': 122,\n",
       " 'second': 144,\n",
       " 'annual': 14,\n",
       " 'ai': 5,\n",
       " '50': 2,\n",
       " 'list': 102,\n",
       " 'of': 116,\n",
       " 'private': 128,\n",
       " 'usbased': 169,\n",
       " 'that': 158,\n",
       " 'are': 18,\n",
       " 'using': 171,\n",
       " 'meaningful': 109,\n",
       " 'businessoriented': 26,\n",
       " 'ways': 178,\n",
       " 'included': 81,\n",
       " 'had': 71,\n",
       " 'privatelyheld': 129,\n",
       " 'focused': 64,\n",
       " 'on': 117,\n",
       " 'techniques': 156,\n",
       " 'like': 101,\n",
       " 'machine': 103,\n",
       " 'learning': 100,\n",
       " 'where': 180,\n",
       " 'systems': 153,\n",
       " 'learn': 99,\n",
       " 'data': 44,\n",
       " 'improve': 79,\n",
       " 'tasks': 154,\n",
       " 'natural': 113,\n",
       " 'language': 95,\n",
       " 'processing': 132,\n",
       " 'which': 181,\n",
       " 'enables': 53,\n",
       " 'programs': 134,\n",
       " 'understand': 167,\n",
       " 'written': 183,\n",
       " 'or': 121,\n",
       " 'spoken': 150,\n",
       " 'computer': 36,\n",
       " 'vision': 176,\n",
       " 'relates': 138,\n",
       " 'how': 74,\n",
       " 'machines': 105,\n",
       " 'see': 145,\n",
       " 'were': 179,\n",
       " 'incubated': 83,\n",
       " 'at': 21,\n",
       " 'largely': 97,\n",
       " 'funded': 68,\n",
       " 'acquired': 4,\n",
       " 'large': 96,\n",
       " 'tech': 155,\n",
       " 'manufacturing': 108,\n",
       " 'industrial': 84,\n",
       " 'including': 82,\n",
       " 'some': 148,\n",
       " 'leading': 98,\n",
       " 'autonomous': 22,\n",
       " 'vehicle': 174,\n",
       " 'developers': 47,\n",
       " 'not': 114,\n",
       " 'eligible': 52,\n",
       " 'consideration': 38,\n",
       " 'was': 177,\n",
       " 'compiled': 35,\n",
       " 'submission': 151,\n",
       " 'process': 131,\n",
       " 'open': 119,\n",
       " 'any': 15,\n",
       " 'company': 33,\n",
       " 'us': 168,\n",
       " 'application': 16,\n",
       " 'asked': 20,\n",
       " 'provide': 135,\n",
       " 'details': 46,\n",
       " 'their': 160,\n",
       " 'business': 25,\n",
       " 'model': 111,\n",
       " 'customers': 42,\n",
       " 'financials': 61,\n",
       " 'funding': 69,\n",
       " 'valuation': 172,\n",
       " 'revenue': 141,\n",
       " 'history': 73,\n",
       " 'option': 120,\n",
       " 'submit': 152,\n",
       " 'information': 86,\n",
       " 'confidentially': 37,\n",
       " 'encourage': 54,\n",
       " 'greater': 70,\n",
       " 'transparency': 166,\n",
       " 'total': 165,\n",
       " 'received': 137,\n",
       " 'about': 3,\n",
       " '400': 1,\n",
       " 'entries': 55,\n",
       " 'there': 162,\n",
       " 'vc': 173,\n",
       " 'partners': 126,\n",
       " 'applied': 17,\n",
       " 'an': 10,\n",
       " 'algorithm': 6,\n",
       " '100': 0,\n",
       " 'highest': 72,\n",
       " 'quantitative': 136,\n",
       " 'scores': 143,\n",
       " 'then': 161,\n",
       " 'panel': 124,\n",
       " 'eight': 51,\n",
       " 'expert': 58,\n",
       " 'judges': 94,\n",
       " 'identified': 76,\n",
       " 'compelling': 34,\n",
       " 'its': 91,\n",
       " 'creating': 40,\n",
       " 'magic': 106,\n",
       " 'algorithms': 7,\n",
       " 'says': 142,\n",
       " 'judge': 93,\n",
       " 'anima': 13,\n",
       " 'anandkumar': 11,\n",
       " 'caltech': 29,\n",
       " 'professor': 133,\n",
       " 'nvidia': 115,\n",
       " 'director': 49,\n",
       " 'machinelearning': 104,\n",
       " 'focus': 63,\n",
       " 'problem': 130,\n",
       " 'impact': 78,\n",
       " 'side': 147}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect1.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['artificial',\n",
       " 'intelligence',\n",
       " 'is',\n",
       " 'beginning',\n",
       " 'to',\n",
       " 'be',\n",
       " 'usefully',\n",
       " 'deployed',\n",
       " 'in',\n",
       " 'almost',\n",
       " 'every',\n",
       " 'industry',\n",
       " 'from',\n",
       " 'customer',\n",
       " 'call',\n",
       " 'centers',\n",
       " 'and',\n",
       " 'finance',\n",
       " 'to',\n",
       " 'drug',\n",
       " 'research',\n",
       " 'yet',\n",
       " 'the',\n",
       " 'field',\n",
       " 'is',\n",
       " 'also',\n",
       " 'plagued',\n",
       " 'by',\n",
       " 'relentless',\n",
       " 'hype',\n",
       " 'opaque',\n",
       " 'jargon',\n",
       " 'and',\n",
       " 'esoteric',\n",
       " 'technology',\n",
       " 'making',\n",
       " 'it',\n",
       " 'difficult',\n",
       " 'for',\n",
       " 'outsiders',\n",
       " 'identify',\n",
       " 'the',\n",
       " 'most',\n",
       " 'interesting',\n",
       " 'companies',\n",
       " 'to',\n",
       " 'cut',\n",
       " 'through',\n",
       " 'the',\n",
       " 'spin',\n",
       " 'forbes',\n",
       " 'partnered',\n",
       " 'with',\n",
       " 'venture',\n",
       " 'firms',\n",
       " 'sequoia',\n",
       " 'capital',\n",
       " 'and',\n",
       " 'meritech',\n",
       " 'capital',\n",
       " 'to',\n",
       " 'create',\n",
       " 'our',\n",
       " 'second',\n",
       " 'annual',\n",
       " 'ai',\n",
       " '50',\n",
       " 'a',\n",
       " 'list',\n",
       " 'of',\n",
       " 'private',\n",
       " 'usbased',\n",
       " 'companies',\n",
       " 'that',\n",
       " 'are',\n",
       " 'using',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " 'in',\n",
       " 'meaningful',\n",
       " 'businessoriented',\n",
       " 'ways',\n",
       " 'to',\n",
       " 'be',\n",
       " 'included',\n",
       " 'companies',\n",
       " 'had',\n",
       " 'to',\n",
       " 'be',\n",
       " 'privatelyheld',\n",
       " 'and',\n",
       " 'focused',\n",
       " 'on',\n",
       " 'techniques',\n",
       " 'like',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'where',\n",
       " 'systems',\n",
       " 'learn',\n",
       " 'from',\n",
       " 'data',\n",
       " 'to',\n",
       " 'improve',\n",
       " 'on',\n",
       " 'tasks',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " 'which',\n",
       " 'enables',\n",
       " 'programs',\n",
       " 'to',\n",
       " '“',\n",
       " 'understand',\n",
       " '”',\n",
       " 'written',\n",
       " 'or',\n",
       " 'spoken',\n",
       " 'language',\n",
       " 'or',\n",
       " 'computer',\n",
       " 'vision',\n",
       " 'which',\n",
       " 'relates',\n",
       " 'to',\n",
       " 'how',\n",
       " 'machines',\n",
       " '“',\n",
       " 'see',\n",
       " '”',\n",
       " 'private',\n",
       " 'ai',\n",
       " 'companies',\n",
       " 'that',\n",
       " 'were',\n",
       " 'incubated',\n",
       " 'at',\n",
       " 'largely',\n",
       " 'funded',\n",
       " 'or',\n",
       " 'acquired',\n",
       " 'by',\n",
       " 'large',\n",
       " 'tech',\n",
       " 'manufacturing',\n",
       " 'or',\n",
       " 'industrial',\n",
       " 'firms–including',\n",
       " 'some',\n",
       " 'of',\n",
       " 'the',\n",
       " 'leading',\n",
       " 'autonomous',\n",
       " 'vehicle',\n",
       " 'developers–were',\n",
       " 'not',\n",
       " 'eligible',\n",
       " 'for',\n",
       " 'consideration',\n",
       " 'the',\n",
       " 'list',\n",
       " 'was',\n",
       " 'compiled',\n",
       " 'through',\n",
       " 'a',\n",
       " 'submission',\n",
       " 'process',\n",
       " 'open',\n",
       " 'to',\n",
       " 'any',\n",
       " 'ai',\n",
       " 'company',\n",
       " 'in',\n",
       " 'the',\n",
       " 'us',\n",
       " 'the',\n",
       " 'application',\n",
       " 'asked',\n",
       " 'companies',\n",
       " 'to',\n",
       " 'provide',\n",
       " 'details',\n",
       " 'on',\n",
       " 'their',\n",
       " 'technology',\n",
       " 'business',\n",
       " 'model',\n",
       " 'customers',\n",
       " 'and',\n",
       " 'financials',\n",
       " 'like',\n",
       " 'funding',\n",
       " 'valuation',\n",
       " 'and',\n",
       " 'revenue',\n",
       " 'history',\n",
       " 'companies',\n",
       " 'had',\n",
       " 'the',\n",
       " 'option',\n",
       " 'to',\n",
       " 'submit',\n",
       " 'information',\n",
       " 'confidentially',\n",
       " 'to',\n",
       " 'encourage',\n",
       " 'greater',\n",
       " 'transparency',\n",
       " 'in',\n",
       " 'total',\n",
       " 'forbes',\n",
       " 'received',\n",
       " 'about',\n",
       " '400',\n",
       " 'entries',\n",
       " 'from',\n",
       " 'there',\n",
       " 'our',\n",
       " 'vc',\n",
       " 'partners',\n",
       " 'applied',\n",
       " 'an',\n",
       " 'algorithm',\n",
       " 'to',\n",
       " 'identify',\n",
       " 'the',\n",
       " '100',\n",
       " 'with',\n",
       " 'the',\n",
       " 'highest',\n",
       " 'quantitative',\n",
       " 'scores',\n",
       " 'and',\n",
       " 'then',\n",
       " 'a',\n",
       " 'panel',\n",
       " 'of',\n",
       " 'eight',\n",
       " 'expert',\n",
       " 'ai',\n",
       " 'judges',\n",
       " 'identified',\n",
       " 'the',\n",
       " '50',\n",
       " 'most',\n",
       " 'compelling',\n",
       " 'companies',\n",
       " '“',\n",
       " 'its',\n",
       " 'not',\n",
       " 'about',\n",
       " 'creating',\n",
       " 'some',\n",
       " 'magic',\n",
       " 'algorithms',\n",
       " '”',\n",
       " 'says',\n",
       " 'judge',\n",
       " 'anima',\n",
       " 'anandkumar',\n",
       " 'a',\n",
       " 'caltech',\n",
       " 'professor',\n",
       " 'and',\n",
       " 'nvidia',\n",
       " '’',\n",
       " 's',\n",
       " 'director',\n",
       " 'of',\n",
       " 'machinelearning',\n",
       " 'research',\n",
       " '“',\n",
       " 'focus',\n",
       " 'on',\n",
       " 'the',\n",
       " 'problem',\n",
       " 'and',\n",
       " 'impact',\n",
       " 'side',\n",
       " '”']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get an article\n",
    "textB = open('article.txt', encoding=\"utf-8\").read()\n",
    "lower_case = textA.lower()\n",
    "# str.maketrans removes any punctuations \n",
    "cleaned_text = lower_case.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "# Using word_tokenize to tokenize sentence into words\n",
    "tokenized_wordsB = word_tokenize(cleaned_text, \"english\")\n",
    "tokenized_wordsB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vector on Document B using BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bag of words : ['100', '400', '50', 'about', 'acquired', 'ai', 'algorithm', 'algorithms', 'almost', 'also', 'an', 'anandkumar', 'and', 'anima', 'annual', 'any', 'application', 'applied', 'are', 'artificial', 'asked', 'at', 'autonomous', 'be', 'beginning', 'business', 'businessoriented', 'by', 'call', 'caltech', 'capital', 'centers', 'companies', 'company', 'compelling', 'compiled', 'computer', 'confidentially', 'consideration', 'create', 'creating', 'customer', 'customers', 'cut', 'data', 'deployed', 'details', 'developers', 'difficult', 'director', 'drug', 'eight', 'eligible', 'enables', 'encourage', 'entries', 'esoteric', 'every', 'expert', 'field', 'finance', 'financials', 'firms', 'focus', 'focused', 'for', 'forbes', 'from', 'funded', 'funding', 'greater', 'had', 'highest', 'history', 'how', 'hype', 'identified', 'identify', 'impact', 'improve', 'in', 'included', 'including', 'incubated', 'industrial', 'industry', 'information', 'intelligence', 'interesting', 'is', 'it', 'its', 'jargon', 'judge', 'judges', 'language', 'large', 'largely', 'leading', 'learn', 'learning', 'like', 'list', 'machine', 'machinelearning', 'machines', 'magic', 'making', 'manufacturing', 'meaningful', 'meritech', 'model', 'most', 'natural', 'not', 'nvidia', 'of', 'on', 'opaque', 'open', 'option', 'or', 'our', 'outsiders', 'panel', 'partnered', 'partners', 'plagued', 'private', 'privatelyheld', 'problem', 'process', 'processing', 'professor', 'programs', 'provide', 'quantitative', 'received', 'relates', 'relentless', 'research', 'revenue', 'says', 'scores', 'second', 'see', 'sequoia', 'side', 'some', 'spin', 'spoken', 'submission', 'submit', 'systems', 'tasks', 'tech', 'techniques', 'technology', 'that', 'the', 'their', 'then', 'there', 'through', 'to', 'total', 'transparency', 'understand', 'us', 'usbased', 'usefully', 'using', 'valuation', 'vc', 'vehicle', 'venture', 'vision', 'was', 'ways', 'were', 'where', 'which', 'with', 'written', 'yet']\n"
     ]
    }
   ],
   "source": [
    "# This step will convert text into tokens \n",
    "vect2 = CountVectorizer()\n",
    "\n",
    "vect2.fit_transform(tokenized_wordsB)\n",
    "print(\"bag of words :\",vect1.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'artificial': 19,\n",
       " 'intelligence': 87,\n",
       " 'is': 89,\n",
       " 'beginning': 24,\n",
       " 'to': 164,\n",
       " 'be': 23,\n",
       " 'usefully': 170,\n",
       " 'deployed': 45,\n",
       " 'in': 80,\n",
       " 'almost': 8,\n",
       " 'every': 57,\n",
       " 'industry': 85,\n",
       " 'from': 67,\n",
       " 'customer': 41,\n",
       " 'call': 28,\n",
       " 'centers': 31,\n",
       " 'and': 12,\n",
       " 'finance': 60,\n",
       " 'drug': 50,\n",
       " 'research': 140,\n",
       " 'yet': 184,\n",
       " 'the': 159,\n",
       " 'field': 59,\n",
       " 'also': 9,\n",
       " 'plagued': 127,\n",
       " 'by': 27,\n",
       " 'relentless': 139,\n",
       " 'hype': 75,\n",
       " 'opaque': 118,\n",
       " 'jargon': 92,\n",
       " 'esoteric': 56,\n",
       " 'technology': 157,\n",
       " 'making': 107,\n",
       " 'it': 90,\n",
       " 'difficult': 48,\n",
       " 'for': 65,\n",
       " 'outsiders': 123,\n",
       " 'identify': 77,\n",
       " 'most': 112,\n",
       " 'interesting': 88,\n",
       " 'companies': 32,\n",
       " 'cut': 43,\n",
       " 'through': 163,\n",
       " 'spin': 149,\n",
       " 'forbes': 66,\n",
       " 'partnered': 125,\n",
       " 'with': 182,\n",
       " 'venture': 175,\n",
       " 'firms': 62,\n",
       " 'sequoia': 146,\n",
       " 'capital': 30,\n",
       " 'meritech': 110,\n",
       " 'create': 39,\n",
       " 'our': 122,\n",
       " 'second': 144,\n",
       " 'annual': 14,\n",
       " 'ai': 5,\n",
       " '50': 2,\n",
       " 'list': 102,\n",
       " 'of': 116,\n",
       " 'private': 128,\n",
       " 'usbased': 169,\n",
       " 'that': 158,\n",
       " 'are': 18,\n",
       " 'using': 171,\n",
       " 'meaningful': 109,\n",
       " 'businessoriented': 26,\n",
       " 'ways': 178,\n",
       " 'included': 81,\n",
       " 'had': 71,\n",
       " 'privatelyheld': 129,\n",
       " 'focused': 64,\n",
       " 'on': 117,\n",
       " 'techniques': 156,\n",
       " 'like': 101,\n",
       " 'machine': 103,\n",
       " 'learning': 100,\n",
       " 'where': 180,\n",
       " 'systems': 153,\n",
       " 'learn': 99,\n",
       " 'data': 44,\n",
       " 'improve': 79,\n",
       " 'tasks': 154,\n",
       " 'natural': 113,\n",
       " 'language': 95,\n",
       " 'processing': 132,\n",
       " 'which': 181,\n",
       " 'enables': 53,\n",
       " 'programs': 134,\n",
       " 'understand': 167,\n",
       " 'written': 183,\n",
       " 'or': 121,\n",
       " 'spoken': 150,\n",
       " 'computer': 36,\n",
       " 'vision': 176,\n",
       " 'relates': 138,\n",
       " 'how': 74,\n",
       " 'machines': 105,\n",
       " 'see': 145,\n",
       " 'were': 179,\n",
       " 'incubated': 83,\n",
       " 'at': 21,\n",
       " 'largely': 97,\n",
       " 'funded': 68,\n",
       " 'acquired': 4,\n",
       " 'large': 96,\n",
       " 'tech': 155,\n",
       " 'manufacturing': 108,\n",
       " 'industrial': 84,\n",
       " 'including': 82,\n",
       " 'some': 148,\n",
       " 'leading': 98,\n",
       " 'autonomous': 22,\n",
       " 'vehicle': 174,\n",
       " 'developers': 47,\n",
       " 'not': 114,\n",
       " 'eligible': 52,\n",
       " 'consideration': 38,\n",
       " 'was': 177,\n",
       " 'compiled': 35,\n",
       " 'submission': 151,\n",
       " 'process': 131,\n",
       " 'open': 119,\n",
       " 'any': 15,\n",
       " 'company': 33,\n",
       " 'us': 168,\n",
       " 'application': 16,\n",
       " 'asked': 20,\n",
       " 'provide': 135,\n",
       " 'details': 46,\n",
       " 'their': 160,\n",
       " 'business': 25,\n",
       " 'model': 111,\n",
       " 'customers': 42,\n",
       " 'financials': 61,\n",
       " 'funding': 69,\n",
       " 'valuation': 172,\n",
       " 'revenue': 141,\n",
       " 'history': 73,\n",
       " 'option': 120,\n",
       " 'submit': 152,\n",
       " 'information': 86,\n",
       " 'confidentially': 37,\n",
       " 'encourage': 54,\n",
       " 'greater': 70,\n",
       " 'transparency': 166,\n",
       " 'total': 165,\n",
       " 'received': 137,\n",
       " 'about': 3,\n",
       " '400': 1,\n",
       " 'entries': 55,\n",
       " 'there': 162,\n",
       " 'vc': 173,\n",
       " 'partners': 126,\n",
       " 'applied': 17,\n",
       " 'an': 10,\n",
       " 'algorithm': 6,\n",
       " '100': 0,\n",
       " 'highest': 72,\n",
       " 'quantitative': 136,\n",
       " 'scores': 143,\n",
       " 'then': 161,\n",
       " 'panel': 124,\n",
       " 'eight': 51,\n",
       " 'expert': 58,\n",
       " 'judges': 94,\n",
       " 'identified': 76,\n",
       " 'compelling': 34,\n",
       " 'its': 91,\n",
       " 'creating': 40,\n",
       " 'magic': 106,\n",
       " 'algorithms': 7,\n",
       " 'says': 142,\n",
       " 'judge': 93,\n",
       " 'anima': 13,\n",
       " 'anandkumar': 11,\n",
       " 'caltech': 29,\n",
       " 'professor': 133,\n",
       " 'nvidia': 115,\n",
       " 'director': 49,\n",
       " 'machinelearning': 104,\n",
       " 'focus': 63,\n",
       " 'problem': 130,\n",
       " 'impact': 78,\n",
       " 'side': 147}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect2.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Fit and transform and predict if the word is present or not .This is widely used for document or subject classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_vect = CountVectorizer()\n",
    "c_vect.fit(tokenized_wordsA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array \n",
      "  [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "features names \n",
      " ['100', '400', '50', 'about', 'acquired', 'ai', 'algorithm', 'algorithms', 'almost', 'also', 'an', 'anandkumar', 'and', 'anima', 'annual', 'any', 'application', 'applied', 'are', 'artificial', 'asked', 'at', 'autonomous', 'be', 'beginning', 'business', 'businessoriented', 'by', 'call', 'caltech', 'capital', 'centers', 'companies', 'company', 'compelling', 'compiled', 'computer', 'confidentially', 'consideration', 'create', 'creating', 'customer', 'customers', 'cut', 'data', 'deployed', 'details', 'developers', 'difficult', 'director', 'drug', 'eight', 'eligible', 'enables', 'encourage', 'entries', 'esoteric', 'every', 'expert', 'field', 'finance', 'financials', 'firms', 'focus', 'focused', 'for', 'forbes', 'from', 'funded', 'funding', 'greater', 'had', 'highest', 'history', 'how', 'hype', 'identified', 'identify', 'impact', 'improve', 'in', 'included', 'including', 'incubated', 'industrial', 'industry', 'information', 'intelligence', 'interesting', 'is', 'it', 'its', 'jargon', 'judge', 'judges', 'language', 'large', 'largely', 'leading', 'learn', 'learning', 'like', 'list', 'machine', 'machinelearning', 'machines', 'magic', 'making', 'manufacturing', 'meaningful', 'meritech', 'model', 'most', 'natural', 'not', 'nvidia', 'of', 'on', 'opaque', 'open', 'option', 'or', 'our', 'outsiders', 'panel', 'partnered', 'partners', 'plagued', 'private', 'privatelyheld', 'problem', 'process', 'processing', 'professor', 'programs', 'provide', 'quantitative', 'received', 'relates', 'relentless', 'research', 'revenue', 'says', 'scores', 'second', 'see', 'sequoia', 'side', 'some', 'spin', 'spoken', 'submission', 'submit', 'systems', 'tasks', 'tech', 'techniques', 'technology', 'that', 'the', 'their', 'then', 'there', 'through', 'to', 'total', 'transparency', 'understand', 'us', 'usbased', 'usefully', 'using', 'valuation', 'vc', 'vehicle', 'venture', 'vision', 'was', 'ways', 'were', 'where', 'which', 'with', 'written', 'yet']\n"
     ]
    }
   ],
   "source": [
    "c_new_vect = c_vect.transform(tokenized_wordsB)\n",
    "\n",
    "print (\"array \\n \",c_new_vect.toarray())\n",
    "\n",
    "# Compare with the indexes\n",
    "print (\"features names \\n\", vect1.get_feature_names() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfidVectorizer for words present of DocB to DocA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfid = TfidfVectorizer(smooth_idf=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "X = vectorizer.fit_transform(tokenized_wordsA)\n",
    "\n",
    "\n",
    "# Testing the TFIDF value + ngrams:\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Testing TFIDF vectorizer without normalization:\n",
    "# You can still specify n-grams here.\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2),norm=None)\n",
    "\n",
    "X = vectorizer.fit_transform(tokenized_wordsA)\n",
    "\n",
    "# Testing TFIDF value before normalization:\n",
    "print(X.toarray())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
